{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM0kuK3SJNKY"
      },
      "outputs": [],
      "source": [
        "### Importar Librer√≠as\n",
        "\n",
        "import torch\n",
        "from torchvision.datasets import Food101\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Subset, Dataset, ConcatDataset\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\"\"\"### Configuraci√≥n inicial\"\"\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# Fijar semillas para reproducibilidad\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\"\"\"### Transformaciones\"\"\"\n",
        "\n",
        "# Transformaci√≥n base (sin data augmentation)\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Transformaci√≥n con data augmentation para entrenamiento\n",
        "augment_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225]),\n",
        "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.3, 3.3))\n",
        "])\n",
        "\n",
        "\"\"\"### Cargar datasets base\"\"\"\n",
        "\n",
        "# Dataset para visualizaci√≥n\n",
        "viz_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "print(\"Cargando datasets...\")\n",
        "train_dataset = Food101(root='.', download=True, split='train', transform=viz_transform)\n",
        "test_dataset = Food101(root='.', download=True, split='test', transform=viz_transform)\n",
        "\n",
        "# Obtener √≠ndices de hot dogs\n",
        "hot_dog_index = train_dataset.classes.index('hot_dog')\n",
        "print(f\"√çndice de 'hot_dog': {hot_dog_index}\")\n",
        "\n",
        "# Obtener todos los √≠ndices\n",
        "targets = train_dataset._labels\n",
        "hotdog_indices = [i for i, label in enumerate(targets) if label == hot_dog_index]\n",
        "not_hotdog_indices = [i for i, label in enumerate(targets) if label != hot_dog_index]\n",
        "\n",
        "test_targets = test_dataset._labels\n",
        "test_hotdog_indices = [i for i, label in enumerate(test_targets) if label == hot_dog_index]\n",
        "test_not_hotdog_indices = [i for i, label in enumerate(test_targets) if label != hot_dog_index]\n",
        "\n",
        "print(f\"\\nDatos disponibles:\")\n",
        "print(f\"Train - Hot dogs: {len(hotdog_indices)}, No hot dogs: {len(not_hotdog_indices)}\")\n",
        "print(f\"Test - Hot dogs: {len(test_hotdog_indices)}, No hot dogs: {len(test_not_hotdog_indices)}\")\n",
        "\n",
        "\"\"\"### Dataset binario personalizado\"\"\"\n",
        "\n",
        "class BinaryFoodDataset(Dataset):\n",
        "    def __init__(self, original_dataset, indices, labels, transform=None):\n",
        "        self.original_dataset = original_dataset\n",
        "        self.indices = indices\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        original_idx = self.indices[idx]\n",
        "\n",
        "        # Obtener imagen PIL del dataset original\n",
        "        image, _ = self.original_dataset[original_idx]\n",
        "\n",
        "        # Convertir tensor a PIL si es necesario\n",
        "        if torch.is_tensor(image):\n",
        "            # Convertir de tensor a PIL\n",
        "            image = transforms.ToPILImage()(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            image = base_transform(image)\n",
        "\n",
        "        label = torch.tensor([self.labels[idx]], dtype=torch.float32)\n",
        "        return image, label\n",
        "\n",
        "\"\"\"### Dataset con repetici√≥n para data augmentation\"\"\"\n",
        "\n",
        "class AugmentedHotdogDataset(Dataset):\n",
        "    def __init__(self, original_dataset, hotdog_indices, target_size, transform):\n",
        "        self.original_dataset = original_dataset\n",
        "        self.hotdog_indices = hotdog_indices\n",
        "        self.target_size = target_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Elegir un hot dog al azar\n",
        "        original_idx = random.choice(self.hotdog_indices)\n",
        "        image, _ = self.original_dataset[original_idx]\n",
        "\n",
        "        # Convertir tensor a PIL si es necesario\n",
        "        if torch.is_tensor(image):\n",
        "            image = transforms.ToPILImage()(image)\n",
        "\n",
        "        image = self.transform(image)\n",
        "        label = torch.tensor([1.0], dtype=torch.float32)\n",
        "        return image, label\n",
        "\n",
        "\"\"\"### Preparar datasets de test (diferentes para cada experimento)\"\"\"\n",
        "\n",
        "def create_balanced_test_loader():\n",
        "    \"\"\"Crea el test loader balanceado para el Experimento 1\"\"\"\n",
        "    random.seed(42)\n",
        "    test_balanced_not_hotdog = random.sample(test_not_hotdog_indices, len(test_hotdog_indices))\n",
        "    test_all_indices = test_hotdog_indices + test_balanced_not_hotdog\n",
        "    test_labels = [1.0] * len(test_hotdog_indices) + [0.0] * len(test_balanced_not_hotdog)\n",
        "\n",
        "    test_binary_ds = BinaryFoodDataset(\n",
        "        test_dataset,\n",
        "        test_all_indices,\n",
        "        test_labels,\n",
        "        transform=base_transform\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(test_binary_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "    print(f\"Test set balanceado: {len(test_binary_ds)} muestras ({len(test_hotdog_indices)} hot dogs, {len(test_balanced_not_hotdog)} no hot dogs)\")\n",
        "    return test_loader\n",
        "\n",
        "def create_full_test_loader():\n",
        "    \"\"\"Crea el test loader completo para los Experimentos 2 y 3\"\"\"\n",
        "    # Usar TODO el conjunto de test\n",
        "    test_all_indices = test_hotdog_indices + test_not_hotdog_indices\n",
        "    test_labels = [1.0] * len(test_hotdog_indices) + [0.0] * len(test_not_hotdog_indices)\n",
        "\n",
        "    test_binary_ds = BinaryFoodDataset(\n",
        "        test_dataset,\n",
        "        test_all_indices,\n",
        "        test_labels,\n",
        "        transform=base_transform\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(test_binary_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "    print(f\"Test set completo: {len(test_binary_ds)} muestras ({len(test_hotdog_indices)} hot dogs, {len(test_not_hotdog_indices)} no hot dogs)\")\n",
        "    return test_loader\n",
        "\n",
        "\"\"\"### Modelo CNN personalizado\"\"\"\n",
        "\n",
        "class CNNBinary(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.features(x))\n",
        "\n",
        "\"\"\"### Funci√≥n de entrenamiento com√∫n\"\"\"\n",
        "\n",
        "def train_model(model, train_loader, test_loader, model_name, n_epochs=5):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"ENTRENANDO: {model_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Limpiar memoria GPU antes de cada entrenamiento\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Reinicializar completamente el modelo\n",
        "    model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
        "\n",
        "    model = model.to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "    best_test_acc = 0.0\n",
        "    results = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî ENTRENAMIENTO ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        avg_loss = total_loss / total_train\n",
        "        train_acc = 100.0 * correct_train / total_train\n",
        "\n",
        "        # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî EVALUACI√ìN ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "        model.eval()\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                correct_test += (predicted == labels).sum().item()\n",
        "                total_test += labels.size(0)\n",
        "\n",
        "        test_acc = 100.0 * correct_test / total_test\n",
        "\n",
        "        if test_acc > best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "        results.append({\n",
        "            'epoch': epoch + 1,\n",
        "            'train_loss': avg_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'test_acc': test_acc\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{n_epochs}: Loss: {avg_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%')\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"\\nTiempo de entrenamiento: {training_time:.2f} segundos\")\n",
        "    print(f\"Mejor Test Accuracy: {best_test_acc:.2f}%\")\n",
        "\n",
        "    return model, results, best_test_acc\n",
        "\n",
        "\"\"\"### Funci√≥n de evaluaci√≥n detallada\"\"\"\n",
        "\n",
        "def evaluate_detailed(model, test_loader, model_name):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probabilities.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_predictions = np.array(all_predictions).flatten()\n",
        "    all_labels = np.array(all_labels).flatten()\n",
        "    all_probabilities = np.array(all_probabilities).flatten()\n",
        "\n",
        "    # Calcular m√©tricas\n",
        "    tp = np.sum((all_predictions == 1) & (all_labels == 1))\n",
        "    tn = np.sum((all_predictions == 0) & (all_labels == 0))\n",
        "    fp = np.sum((all_predictions == 1) & (all_labels == 0))\n",
        "    fn = np.sum((all_predictions == 0) & (all_labels == 1))\n",
        "\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    print(f\"\\n{model_name} - Resultados detallados:\")\n",
        "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "    print(f\"Precision: {precision:.3f}\")\n",
        "    print(f\"Recall: {recall:.3f}\")\n",
        "    print(f\"F1-Score: {f1:.3f}\")\n",
        "    print(f\"TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn\n",
        "    }\n",
        "\n",
        "\"\"\"### EXPERIMENTO 1: Balanceo b√°sico (750 muestras cada clase) - Test balanceado\"\"\"\n",
        "\n",
        "def experiment_1():\n",
        "    print(f\"\\nüî• EXPERIMENTO 1: BALANCEO B√ÅSICO (750 + 750) - TEST BALANCEADO\")\n",
        "\n",
        "    # Limpiar memoria antes del experimento\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Usar solo 750 hot dogs - nueva semilla para este experimento\n",
        "    random.seed(42)\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    selected_hotdog_indices = random.sample(hotdog_indices, 750)\n",
        "    selected_not_hotdog_indices = random.sample(not_hotdog_indices, 750)\n",
        "\n",
        "    # Crear dataset\n",
        "    train_indices = selected_hotdog_indices + selected_not_hotdog_indices\n",
        "    train_labels = [1.0] * 750 + [0.0] * 750\n",
        "\n",
        "    train_ds = BinaryFoodDataset(\n",
        "        train_dataset,\n",
        "        train_indices,\n",
        "        train_labels,\n",
        "        transform=base_transform\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "    # Crear test loader balanceado\n",
        "    test_loader = create_balanced_test_loader()\n",
        "\n",
        "    print(f\"Dataset de entrenamiento: {len(train_ds)} muestras\")\n",
        "\n",
        "    # Crear NUEVO modelo CNN desde cero\n",
        "    model1 = CNNBinary()\n",
        "    print(\"‚úÖ Modelo CNN creado desde cero para Experimento 1\")\n",
        "\n",
        "    model1, results, best_acc = train_model(model1, train_loader, test_loader, \"CNN con Balanceo B√°sico\")\n",
        "\n",
        "    # Limpiar despu√©s del entrenamiento\n",
        "    del train_loader, train_ds\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return model1, results, best_acc, test_loader\n",
        "\n",
        "\"\"\"### EXPERIMENTO 2: Data Augmentation (10,000 muestras cada clase) - Test completo\"\"\"\n",
        "\n",
        "def experiment_2():\n",
        "    print(f\"\\nüöÄ EXPERIMENTO 2: DATA AUGMENTATION (10,000 + 10,000) - TEST COMPLETO\")\n",
        "\n",
        "    # Limpiar memoria antes del experimento\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Reinicializar semillas para este experimento\n",
        "    random.seed(123)  # Diferente semilla\n",
        "    torch.manual_seed(123)\n",
        "\n",
        "    # Dataset aumentado de hot dogs\n",
        "    hotdog_augmented_ds = AugmentedHotdogDataset(\n",
        "        train_dataset,\n",
        "        hotdog_indices,\n",
        "        target_size=10000,\n",
        "        transform=augment_transform\n",
        "    )\n",
        "\n",
        "    # Dataset de no-hot-dogs (10,000 muestras)\n",
        "    selected_not_hotdog_indices = random.sample(not_hotdog_indices, 10000)\n",
        "    not_hotdog_labels = [0.0] * 10000\n",
        "\n",
        "    not_hotdog_ds = BinaryFoodDataset(\n",
        "        train_dataset,\n",
        "        selected_not_hotdog_indices,\n",
        "        not_hotdog_labels,\n",
        "        transform=augment_transform\n",
        "    )\n",
        "\n",
        "    # Combinar datasets\n",
        "    combined_ds = ConcatDataset([hotdog_augmented_ds, not_hotdog_ds])\n",
        "    train_loader = DataLoader(combined_ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "    # Crear test loader completo\n",
        "    test_loader = create_full_test_loader()\n",
        "\n",
        "    print(f\"Dataset de entrenamiento: {len(combined_ds)} muestras\")\n",
        "\n",
        "    # Crear NUEVO modelo CNN desde cero\n",
        "    model2 = CNNBinary()\n",
        "    print(\"‚úÖ Modelo CNN creado desde cero para Experimento 2\")\n",
        "\n",
        "    model2, results, best_acc = train_model(model2, train_loader, test_loader, \"CNN con Data Augmentation\", n_epochs=7)\n",
        "\n",
        "    # Limpiar despu√©s del entrenamiento\n",
        "    del train_loader, combined_ds, hotdog_augmented_ds, not_hotdog_ds\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return model2, results, best_acc, test_loader\n",
        "\n",
        "\"\"\"### EXPERIMENTO 3: ResNet18 Preentrenado - Test completo\"\"\"\n",
        "\n",
        "def experiment_3():\n",
        "    print(f\"\\nüéØ EXPERIMENTO 3: RESNET18 PREENTRENADO (10,000 + 10,000) - TEST COMPLETO\")\n",
        "\n",
        "    # Limpiar memoria antes del experimento\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Reinicializar semillas para este experimento\n",
        "    random.seed(456)  # Diferente semilla\n",
        "    torch.manual_seed(456)\n",
        "\n",
        "    # Dataset aumentado de hot dogs\n",
        "    hotdog_augmented_ds = AugmentedHotdogDataset(\n",
        "        train_dataset,\n",
        "        hotdog_indices,\n",
        "        target_size=10000,\n",
        "        transform=augment_transform\n",
        "    )\n",
        "\n",
        "    selected_not_hotdog_indices = random.sample(not_hotdog_indices, 10000)\n",
        "    not_hotdog_labels = [0.0] * 10000\n",
        "\n",
        "    not_hotdog_ds = BinaryFoodDataset(\n",
        "        train_dataset,\n",
        "        selected_not_hotdog_indices,\n",
        "        not_hotdog_labels,\n",
        "        transform=augment_transform\n",
        "    )\n",
        "\n",
        "    combined_ds = ConcatDataset([hotdog_augmented_ds, not_hotdog_ds])\n",
        "    train_loader = DataLoader(combined_ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "    # Crear test loader completo\n",
        "    test_loader = create_full_test_loader()\n",
        "\n",
        "    print(f\"Dataset de entrenamiento: {len(combined_ds)} muestras\")\n",
        "\n",
        "    # Crear NUEVO modelo ResNet18 desde cero\n",
        "    model3 = models.resnet18(pretrained=True)\n",
        "    print(\"‚úÖ Modelo ResNet18 cargado NUEVO desde pretrained para Experimento 3\")\n",
        "\n",
        "    # Fine-tuning: descongelar √∫ltimas capas\n",
        "    for param in model3.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Descongelar las √∫ltimas capas\n",
        "    for param in model3.layer4.parameters():\n",
        "        param.requires_grad = True\n",
        "    for param in model3.avgpool.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # Reemplazar la √∫ltima capa\n",
        "    num_features = model3.fc.in_features\n",
        "    model3.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(num_features, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    model3, results, best_acc = train_model(model3, train_loader, test_loader, \"ResNet18 Preentrenado\", n_epochs=7)\n",
        "\n",
        "    # Limpiar despu√©s del entrenamiento\n",
        "    del train_loader, combined_ds, hotdog_augmented_ds, not_hotdog_ds\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return model3, results, best_acc, test_loader\n",
        "\n",
        "\"\"\"### Funci√≥n principal para ejecutar todos los experimentos\"\"\"\n",
        "\n",
        "def run_all_experiments():\n",
        "    results_summary = []\n",
        "\n",
        "    print(\"üî•üöÄüéØ INICIANDO LOS 3 EXPERIMENTOS üéØüöÄüî•\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Experimento 1 - Test balanceado\n",
        "    model1, results1, best_acc1, test_loader1 = experiment_1()\n",
        "    detailed1 = evaluate_detailed(model1, test_loader1, \"Experimento 1\")\n",
        "    results_summary.append((\"Balanceo B√°sico (750+750) - Test Balanceado\", best_acc1, detailed1))\n",
        "\n",
        "    # Experimento 2 - Test completo\n",
        "    model2, results2, best_acc2, test_loader2 = experiment_2()\n",
        "    detailed2 = evaluate_detailed(model2, test_loader2, \"Experimento 2\")\n",
        "    results_summary.append((\"Data Augmentation (10k+10k) - Test Completo\", best_acc2, detailed2))\n",
        "\n",
        "    # Experimento 3 - Test completo\n",
        "    model3, results3, best_acc3, test_loader3 = experiment_3()\n",
        "    detailed3 = evaluate_detailed(model3, test_loader3, \"Experimento 3\")\n",
        "    results_summary.append((\"ResNet18 Preentrenado (10k+10k) - Test Completo\", best_acc3, detailed3))\n",
        "\n",
        "    # Resumen final\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"üèÜ RESUMEN FINAL DE TODOS LOS EXPERIMENTOS üèÜ\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    for i, (name, best_acc, detailed) in enumerate(results_summary, 1):\n",
        "        print(f\"\\n{i}. {name}:\")\n",
        "        print(f\"   Mejor Test Accuracy: {best_acc:.2f}%\")\n",
        "        print(f\"   Precision: {detailed['precision']:.3f}\")\n",
        "        print(f\"   Recall: {detailed['recall']:.3f}\")\n",
        "        print(f\"   F1-Score: {detailed['f1']:.3f}\")\n",
        "\n",
        "    # Encontrar el mejor (considerando que el Experimento 1 usa test diferente)\n",
        "    print(f\"\\nüìä NOTA IMPORTANTE:\")\n",
        "    print(f\"   - Experimento 1: Usa test balanceado (250 hot dogs + 250 no hot dogs)\")\n",
        "    print(f\"   - Experimentos 2 y 3: Usan test completo (250 hot dogs + 24,750 no hot dogs)\")\n",
        "    print(f\"   - Los resultados NO son directamente comparables debido a la diferencia en distribuci√≥n\")\n",
        "\n",
        "    best_balanced = results_summary[0]  # Experimento 1\n",
        "    best_full = max(results_summary[1:], key=lambda x: x[1])  # Experimentos 2 y 3\n",
        "\n",
        "    print(f\"\\nü•á MEJOR en Test Balanceado: {best_balanced[0]} con {best_balanced[1]:.2f}%\")\n",
        "    print(f\"ü•á MEJOR en Test Completo: {best_full[0]} con {best_full[1]:.2f}%\")\n",
        "\n",
        "    return results_summary\n",
        "\n",
        "\"\"\"### Ejecutar todos los experimentos\"\"\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = run_all_experiments()"
      ]
    }
  ]
}